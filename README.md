# Kato M., et al., 2025
Analysis scripts and codes for reproducing figures in the manuscript Systematic image perturbations reveal persistent gaps between biological and machine vision

## Organization

### **analysis/**
Figures generated by scripts in the `codes/` folder are saved here. Some folders also contain intermediate files to reduce computation time.

### **codes/**
Code to reproduce the figures. To generate the figures, set the `rootD` variable at the top of each script to the project home directory (the directory containing this README), then run the scripts.

### **stim/**
#### **stim/codes/** 
Codes used to generate the image set. To generate the image set, set `rootD` at the top of each script to the directory containing this `stim` folder in your environment, then run the scripts sequentially from step1 to step6. The code that generates Tex images is available at [texture_synthesis](https://github.com/LefdRida/texture_synthesis). The only modification we made was target layers: change from `layers = ["conv1_1", "pool1", "pool2", "pool3", "pool4"]` to `layers = ["conv1_1","conv1_2", "pool1","conv2_1","conv2_2", "pool2"]`. Line-drawings were generated using [informative-drawings](https://github.com/carolineec/informative-drawings), with the `style` option set to `anime`

#### **stim/rawim/**
Raw images were taken from the validation set of the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012. Due to copyright restrictions, we include only the raw images used to generate the example images shown in Fig. 1a and Fig. S1c; these images are not part of the stimulus set used in the experiments. The full stimulus set can be provided upon reasonable request and in accordance with ImageNetâ€™s terms of access.
We provide ImageNet image IDs (`ImageNet_image_IDs.csv`) and background masks. Once the listed images are placed in this folder, the provided scripts and masks will allow you to reproduce all images.

#### **stim/mask/**
Background masks used to isolate objects.

#### **stim/genim/**
Generated images used in the experiments. Only the example images shown in Fig. 1a and Fig. S1c are included.

#### **stim/imagenet_subclass/**
`{Category label}.csv` lists ImageNet classes mapped to that category, defined using the WordNet lexical hierarchy. For example, when evaluating DNN predictions for the category `bear`, the following ImageNet classes were considered correct:

| WordNet synset ID   | ImageNet class |
| -------- | ------- |
|n02134418|	sloth_bear|
|n02134084|	ice_bear|
|n02133161|	american_black_bear|
|n02132136|	brown_bear|

`{Category label}_list.csv` lists human answers counted as correct (first column) and incorrect (second column).

### **rawdata/**
This folder includes the following data:
- human raw responses in Exp1 and Exp2 (`behav_exp1/` and `behav_exp2/`)
- DNNs' top-1 predictions (`class/`)
- IT predictability of each DNN, obtained from [Brain-score](https://www.brain-score.org/vision/leaderboard) (`benchmark_scores.csv`)
- DNN labels used in large scale analysis in Figs.3 and 4 (`DNNlabels.mat`)
